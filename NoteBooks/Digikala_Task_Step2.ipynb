{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c6ca2fb-c728-484d-a664-4c48871a4ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import torch\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sentence_transformers import util\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "afaea9fd-2d77-4321-ad1a-ccd1d6e1a029",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data_step1.csv\", low_memory=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b595267a-b20d-49bc-8d1f-d3a6a7c3a4f7",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### drop id and product description, not needed any more"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fe43a858-600a-4e25-81e2-a4e90ac15030",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(df.columns[[0, 1]], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8b15ac9-8dfe-4523-bf9b-9dfcd5c7b472",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Delete wrong data in each column using the clusters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "009802f7-49d0-49ee-b13d-6965963bc0b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column Number: 2\n",
      " Values for دارای مبدل grouped by دارای مبدل_cluster_labels:\n",
      "دارای مبدل_cluster_labels\n",
      "0    [nan, nan, nan, nan, nan, nan, nan, nan, nan, ...\n",
      "1    [('استرالیا و چین', 'اروپا', 'آمریکا و ژاپن'),...\n",
      "2    [('آمریکا و ژاپن',), ('اروپا',), ('آمریکا و ژا...\n",
      "Name: دارای مبدل, dtype: object\n",
      "\n",
      "\n",
      "Column Number: 3\n",
      " Values for مدل grouped by مدل_cluster_labels:\n",
      "مدل_cluster_labels\n",
      "-1    [E5-2640 v2, E5-2695 v2, E5-2670 V2, E5-2680 v...\n",
      " 0    [nan, nan, nan, nan, nan, nan, nan, nan, nan, ...\n",
      " 1                  [Ivy Bridge, Haswell , Surface Duo]\n",
      " 2                                [شارژی, هشت عدد, چوب]\n",
      "Name: مدل, dtype: object\n",
      "\n",
      "\n",
      "Column Number: 4\n",
      " Values for هشدار ها grouped by هشدار ها_cluster_labels:\n",
      "هشدار ها_cluster_labels\n",
      "-1    [پشتیبانی از شبکههای GPS: A-GPS/GLONASS/Galile...\n",
      " 0    [nan, nan, nan, nan, nan, nan, nan, nan, nan, ...\n",
      " 1    [قابلیت نمایش اعلانهای مختلف پیامک، تماس، تمام...\n",
      " 2    [جهت سینک شدن ساعت و گوشی از کد سه بعدی داخل س...\n",
      "Name: هشدار ها, dtype: object\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "###check each column clusters to see valid data\n",
    "for i in range(2,5):\n",
    "    column_i = df.columns[i]\n",
    "    column_i_1228 = df.columns[i + 1228]\n",
    "\n",
    "    grouped = df.groupby(column_i_1228)[column_i].agg(list)\n",
    "\n",
    "    # Display the result for each cluster\n",
    "    print(f\"Column Number: {df.columns.get_loc(column_i)}\\n Values for {column_i} grouped by {column_i_1228}:\")\n",
    "    print(grouped)\n",
    "    print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "742eb5e0-761e-4a5f-a615-b99a459a4164",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Usnig bert first but not applicable enough"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "e3876bcd-6f39-4b6a-815d-23c1ca0d30b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "###Find Similarity of cluster'value with column name, using a persian BERT\n",
    "\n",
    "def text_embedding(text, model, batch_size=32, use_cpu=True):\n",
    "    try:\n",
    "        # Encode text and move the tensor to CPU before converting to numpy\n",
    "        if use_cpu:\n",
    "            embeddings = model.encode(text, convert_to_tensor=True, batch_size=batch_size, device='cpu').detach().numpy()\n",
    "        else:\n",
    "            # Explicitly free GPU memory after encoding\n",
    "            with torch.no_grad():\n",
    "                embeddings = model.encode(text, convert_to_tensor=True, batch_size=batch_size).cpu().detach().numpy()\n",
    "        \n",
    "        # Use flatten instead of reshape\n",
    "        embeddings = embeddings.flatten()\n",
    "        return embeddings\n",
    "    except Exception as e:\n",
    "        print(f\"Error occurred during encoding: {e}\")\n",
    "        return None\n",
    "\n",
    "def calculate_similarity(embedding1, embedding2):\n",
    "    # return cosine_similarity(embedding1.reshape(1, -1), embedding2.reshape(1, -1))[0][0]\n",
    "    return util.pytorch_cos_sim(embedding1, embedding2)[0][0].item()\n",
    "\n",
    "\n",
    "def check_semantic_similarity(df, column_number, cluster_labels_column, model, threshold=0.3):\n",
    "\n",
    "    # Get the column name based on the column number\n",
    "    column_name = df.columns[column_number]\n",
    "    column_embedding = text_embedding(column_name, model)\n",
    "\n",
    "    # Get cluster labels from the specified column\n",
    "    cluster_labels = df.iloc[:, cluster_labels_column]\n",
    "\n",
    "    # Group by the cluster labels\n",
    "    grouped = df.groupby(cluster_labels)[column_name].agg(list)\n",
    "\n",
    "    # Iterate over clusters\n",
    "    for target_cluster, target_cluster_list in grouped.items():\n",
    "        # Check if the cluster label is not -1\n",
    "        if target_cluster != -1:\n",
    "            # Check if there is data in the list\n",
    "            if target_cluster_list:\n",
    "                # Get the first value in the list\n",
    "                first_value = str(target_cluster_list[0])  # Convert to string to handle numerical values\n",
    "\n",
    "                # Check if the first value is not nan\n",
    "                if first_value.lower() != 'nan':\n",
    "                    # Calculate text embeddings using SentenceTransformer\n",
    "                    # column_embedding = text_embedding(column_name, model)\n",
    "                    first_value_embedding = text_embedding(first_value, model)\n",
    "\n",
    "                    # Check if embeddings were successfully obtained\n",
    "                    if column_embedding is not None and first_value_embedding is not None:\n",
    "                        # Calculate cosine similarity\n",
    "                        similarity_score = calculate_similarity(column_embedding, first_value_embedding)\n",
    "\n",
    "                        # Check if the similarity score is above the threshold\n",
    "                        is_related_semantically = similarity_score > threshold\n",
    "\n",
    "                        # Display the result\n",
    "                        print(f\"Is the first value '{first_value}' in cluster {target_cluster} related to column {column_number} '{column_name}'? {is_related_semantically} (Similarity Score: {similarity_score})\")\n",
    "                else:\n",
    "                    print(f\"The first value in cluster {target_cluster} was 'nan'.\")\n",
    "            else:\n",
    "                print(f\"No data found for cluster {target_cluster}.\")\n",
    "        else:\n",
    "            print(f\"Skipping cluster {target_cluster}.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "1311d4ec-5630-45e6-a958-e45d9671e8ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No sentence-transformers model found with name /home/salvia/.cache/torch/sentence_transformers/m3hrdadfi_bert-fa-base-uncased-wikitriplet-mean-tokens. Creating a new one with MEAN pooling.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping cluster -1.\n",
      "The first value in cluster 0 was 'nan'.\n",
      "-----------------------\n",
      "The first value in cluster 0 was 'nan'.\n",
      "Is the first value 'شیشه' in cluster 1 related to column 21 'جنس فیلتر'? True (Similarity Score: 0.5647438168525696)\n",
      "Is the first value 'شیشه AGC' in cluster 2 related to column 21 'جنس فیلتر'? True (Similarity Score: 0.5990363359451294)\n",
      "-----------------------\n",
      "Skipping cluster -1.\n",
      "The first value in cluster 0 was 'nan'.\n",
      "Is the first value 'Sequans' in cluster 1 related to column 22 'مدل چیپست'? True (Similarity Score: 0.3974950909614563)\n",
      "Is the first value 'Huawei' in cluster 2 related to column 22 'مدل چیپست'? True (Similarity Score: 0.4286998510360718)\n",
      "-----------------------\n",
      "Skipping cluster -1.\n",
      "The first value in cluster 0 was 'nan'.\n",
      "Is the first value 'پلاستیک' in cluster 1 related to column 23 'جنس فیس پلیت'? True (Similarity Score: 0.6840038299560547)\n",
      "Is the first value 'فلزی' in cluster 2 related to column 23 'جنس فیس پلیت'? True (Similarity Score: 0.5758523941040039)\n",
      "-----------------------\n",
      "The first value in cluster 0 was 'nan'.\n",
      "Is the first value '('بدون درایو نوری',)' in cluster 1 related to column 24 'درایو نوری'? True (Similarity Score: 0.7443562746047974)\n",
      "Is the first value '('DVD-RW',)' in cluster 2 related to column 24 'درایو نوری'? True (Similarity Score: 0.5613701343536377)\n",
      "-----------------------\n"
     ]
    }
   ],
   "source": [
    "### Try different modele and apply\n",
    "# Load SentenceTransformer model\n",
    "model_name = '/home/salvia/.cache/torch/sentence_transformers/m3hrdadfi_bert-fa-base-uncased-wikitriplet-mean-tokens'\n",
    "# model_name = '/home/salvia/.cache/torch/sentence_transformers/sentence-transformers/bert-base-nli-stsb-mean-tokens'\n",
    "# model_name='sentence-transformers/use-cmlm-multilingual'\n",
    "\n",
    "# model_name='/home/salvia/.cache/torch/sentence_transformers/HooshvareLab_bert-base-parsbert-uncased'\n",
    "model = SentenceTransformer(model_name)\n",
    "\n",
    "for column_number in range(20,25):\n",
    "    cluster_labels_column = column_number + 1228  # Assuming the cluster labels start from column 1457\n",
    "    check_semantic_similarity(df, column_number, cluster_labels_column, model, 0.3)\n",
    "    print(\"-----------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d276a65-3566-4f98-969e-92a972a16686",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Delete the cluster anomali Manually, and save unrelated data to delete them from all the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "676a52d3-900a-401f-92a4-44898855c797",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Delete the cluster anomali manually, and save unrelated data to delete them from all the dataset\n",
    "def set_cluster_data_to_nan_multiple(df, column_indices, cluster_numbers_list):\n",
    "    updates_dict = dict(zip(column_indices, cluster_numbers_list))\n",
    "    \n",
    "    # Create a set to store the data before making it NaN\n",
    "    data_before_nan = set()\n",
    "\n",
    "    for update in updates_dict.items():\n",
    "        column_index, cluster_numbers = update\n",
    "\n",
    "        for cluster_number in cluster_numbers:\n",
    "            # Identify rows with the specified cluster in the specified column using iloc\n",
    "            rows_to_update = df[df.iloc[:, column_index + 1228] == cluster_number].index\n",
    "\n",
    "            # Store the cell values before making them NaN\n",
    "            data_before_nan.update(set(df.loc[rows_to_update, df.columns[column_index]].values))\n",
    "\n",
    "            # Set the values in the specified column to NaN for the identified rows\n",
    "            df.loc[rows_to_update, df.columns[column_index]] = np.nan\n",
    "\n",
    "    return df, data_before_nan\n",
    "\n",
    "column_indices = [2, 3, 5,6,7,10,13,17,18,30,38,40,47,49,52,53,54,61,62,72,78,79,86,89,92,97,98,106,107,108, 1035]\n",
    "cluster_numbers_list = [[1, 2], [2], [1,2],[1,2],[2],[1,2],[1,2],[1,2],[2],[1,2],[1,2],[1],[1,2],[1,2],[1,2],[1,2],[1,2],[1,2],[1,2],[1,2],[1,2],[1,2],[1,2],[1],[1,2],[1,2],[1,2],[1,2],[1,2],[1,2],[0,1,2],[1,2]]\n",
    "\n",
    "df, data_before_nan = set_cluster_data_to_nan_multiple(df, column_indices, cluster_numbers_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f7181f42-4018-4f14-b418-f3273896e969",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Delete all anomaly data\n",
    "def trace_and_set_to_nan(df, data_before_nan):\n",
    "    # for col in df.columns:\n",
    "    for col in df.columns[2:1229]:\n",
    "        for index, cell_value in df[col].items():\n",
    "            # Check if the cell value is in the set data_before_nan\n",
    "            if cell_value in data_before_nan:\n",
    "                df.at[index, col] = np.nan\n",
    "\n",
    "    return df\n",
    "    \n",
    "df = trace_and_set_to_nan(df, data_before_nan)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85117db0-da2e-4134-9bb8-55be2d80ad9a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Delete full null, and cluster cols not needed any more"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "707b1402-64cb-464a-9d1c-0cf1e5a44aff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop columns from 1231 to the end: All extra columns for clustering value,any more neeaded\n",
    "df = df.drop(df.columns[1229:], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d117b311-c629-432e-9876-127b2d264b47",
   "metadata": {},
   "outputs": [],
   "source": [
    "### delete nan columns and nan rows\n",
    "df = df.dropna(axis=1, how='all')  # Drop NaN columns\n",
    "df = df.dropna(axis=0, how='all')  # Drop NaN rows"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54f78357-9dfa-400c-bbc4-243be845db8f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Save result to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e962f6bd-ce00-455f-9a86-fedf2861a4a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('data_step2.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "My Virtual Environment",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
